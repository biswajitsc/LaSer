Relevance experiments

A comparison between three Web search engines

In spring 1999, I made a small comparison study between three search engines, the well-known Alta Vista (http://www.altavista.com), and two newcomers, AllTheWeb (http://www.alltheweb.com) and Google (http://www.google.com). Twelve queries were sent to the engines, and the 10 first retrieved documents evaluated. Ten of the queries were fetched from a similar study made by Clarke and Willet [ClaWil97], the last two were formulated by myself. All the relevance assignments were done by me.
I used a three point relevance scale, relevant (1), partly relevant (0.5) and not relevant (0). To be deemed relevant, a page would have to closely match the query, and give some information about it. A partly relevant page was defined as either a page giving information on where to get information (a hypertext link, an address or a reference to a book or article about the subject), or some information connected to the query, but not quite to the point. Pages not containing any information about the query topic, were deemed not relevant, even if they contained information connected to some of the query terms (when the query was "the name of the king of Norway in 1990", information about ancient Norwegian kings were assigned the 0 score).

Mirror pages, which contain the same information, but have a different URL were counted as ordinary pages, whereas copy pages (same contents and same URL) got 0 score, since the user is certainly not interested in such links. Also error reports, such as not existing page or no response got the 0 score (no response pages after some additional trials). The exception was Google, which has a cache facility making me able to evaluate even such pages.

From the results, the mean precision (P@10) of each engine was estimated. When counting only the relevant, not the partly relevant documents, I got precision rates 0.4 for Alta Vista, 0.7 for Google, and 0.4 for AllTheWeb. Counting also the partly relevant documents, the mean precisions were 0.5 (Alta Vista), 0.9 (Google) and 0.5 (AllTheWeb). An analysis of variance showed no statistical significant difference between the precisions at the 0.05 level when counting only the relevant documents, whereas taking also the partly relevant documents into account gave a statistical significant difference (F=4.5 compared to F0.05,2,31= 3.3) between the engines.

The total sum of relevant pages was defined as the sum of the relevant, retrieved documents over all the three engines, counting equal documents found by two or more engines only once. Using this number as the denominator, the mean pooled recall was estimated to 0.3 (Alta Vista), 0.5 (Google) and 0.3 (AllTheWeb). Analysis of variance showed no significant differences.

Counting how many times the highest ranked document is deemed relevant for the twelve queries, the probability of getting a relevant document as the first, was estimated to 0.3 (Alta Vista), 0.8 (Google) and 0.5 (AllTheWeb). An approximate test based on the X2 statistics, showed no significant differences in these probabilities. However, taking also the partly relevant documents into account, the probability of getting a (partly) relevant document as the first, was estimated to 0.5 (Alta Vista), 1.0 (Google) and 0.7 (AllTheWeb). This gave a significant difference in the X2 test, but since the numbers of observations are small, this test is questionable.

(source : http://www.aitel.hist.no/~mildrid/dring/paper/SIGIR.html)